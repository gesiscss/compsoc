{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](index.ipynb) > [Data Transformation](data_transformation.ipynb) > Meaning structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style='float: left;' src='https://www.gesis.org/fileadmin/styles/img/gs_home_logo_en.svg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ``compsoc`` – *Notebooks for Computational Sociology* (alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meaning structures: Bipartite matrix projection\n",
    "Authors: [Haiko Lietz](https://www.gesis.org/person/haiko.lietz)\n",
    "\n",
    "Version: 0.91 (14.09.2020)\n",
    "\n",
    "Please cite as: Lietz, Haiko (2020). Meaning structures: Bipartite matrix projection. Version 0.91 (14.09.2020). *compsoc – Notebooks for Computational Sociology*. GESIS. url:[github.com/gesiscss/compsoc](https://github.com/gesiscss/compsoc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'>\n",
    "<big><b>Significance</b></big>\n",
    "\n",
    "Bla.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "According to the model of complex socio-cultural systems sketched in the introduction, transactions resemble the building blocks of these systems. From all the transactions in a field, a patterned macrobehavior emerges that provides expectations or meaning for future microbehavior. We refer to such structures as meaning structures (Mohr, xxxx). To get a grip on this concept, we mapped the systems model to a unified model for digital behavioral data. The fundamental idea is that agents make transactions and transactions select facts. The latter notion expresses the duality that a selection is both a top-down and a bottom-up hypothesis. In downward causation, selection expresses how agents are influenced by emergent facts -- in Padgett & Powell's (2012) words, \"relations make actors\"; as part of emergence, selection expresses how agents are free to chose facts -- \"actors make relations\".\n",
    "\n",
    "... Social and cultural meaning structures ... agency\n",
    "\n",
    "White's market profiles\n",
    "\n",
    "cores... Fuchs\n",
    "\n",
    "Flack's power distributions\n",
    "\n",
    "Zipf's Law\n",
    "\n",
    "communities and blocks\n",
    "\n",
    "catalysis\n",
    "\n",
    "attention economics\n",
    "\n",
    "Breiger\n",
    "\n",
    "domains... types of tie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|<img src='images/lietz_2020_fig2.png' style='float: none; width: 500px'>|\n",
    "|:--|\n",
    "|<em style='float: center'>**Figure 1**: Mapping of socio-cultural systems model to mathematical framework (fig. 2 in Lietz, 2020)</em>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this notebook**, we demonstrate how we can use the unified data model to study the meaning encoded in networks. We will lay out a core part of the ``compsoc`` mathematical framework (figure 1). We will see how digital behavioral data can be naturally represented by bipartite matrices, how meaning structures can be obtained by projecting these matrices, how matrix normalization can be used to account for potential behavioral differences in subfields, and how matrix algebra and community detection go hand in hand to uncover multiple layers or domains of social life from data. Two basic functions will be developed. They are largely based on the mathematical framework developed by Batagelj and Cerinšek (2013). Lietz (2020, particularly the [technical appendix](https://link.springer.com/article/10.1007/s11192-020-03527-0#appendices)) can be read to gain traction on the formalism used in this notebook. To be able to process large data collections, this notebook uses sparse matrix methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import compsoc as cs\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the basic formalism\n",
    "A simple toy model shall help us to keep things simple and understandable. It contains only the most central aspects of transactions selecting facts and transactions belonging to domains:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|<img src='images/data_model_toy.png' style='float: none; width: 380px'>|\n",
    "|:--|\n",
    "|<em style='float: center'>**Figure 2**: Subset of unified model for digital behavioral data</em>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data, depicted in figure 1, resembles a field that consists of $m=5$ distinct transactions. Our computational framework requires that identifiers are integers from $0$ to $m-1$. Transactions are stored in a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = [[0, '1', 0], [1, '2', 0], [2, '3', 1], [3, '4', 1], [4, '5', 1]]\n",
    "transactions = pd.DataFrame(transactions, columns=['transaction_id', 'transaction', 'domain_id'])\n",
    "transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this field, $n=9$ distinct facts are selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts = [[0, '1'], [1, '2'], [2, '3'], [3, '4'], [4, '5'], [5, '6'], [6, '7'], [7, '8'], [8, '9']]\n",
    "facts = pd.DataFrame(facts, columns=['fact_id', 'fact'])\n",
    "facts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, there are $15$ selections. Note that all transactions select a different number of overlapping facts; in the transaction with ``transaction_id=0``, five facts are selected; ``transaction_id=1`` selects four facts; etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selections = [[0, 0, 1], [0, 1, 1], [0, 2, 1], [0, 3, 1], [0, 4, 1]]\n",
    "selections = [[0, 0, 1], [0, 1, 1], [0, 2, 1], [0, 3, 1], [0, 4, 1], [1, 2, 1], [1, 3, 1], [1, 4, 1], [1, 5, 1], [2, 4, 1], [2, 5, 1], [2, 6, 1], [3, 6, 1], [3, 7, 1], [4, 8, 1]]\n",
    "selections = pd.DataFrame(selections, columns=['transaction_id', 'fact_id', 'weight'])\n",
    "selections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``selections`` dataframe contains all the information we need to create the bipartite **selection matrix** $G$. Since all transaction and fact identifiers are present, $G$ is an $m\\times n$ matrix where ``weight`` gives the strength or number of times that a transaction is selecting a fact.\n",
    "\n",
    "We use the ``scipy.sparse`` package to handle matrices. It uses different formats to store information that have advantages and drawback for certain tasks. For matrix construction, the [COOrdinate](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html) format is intended:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, coo_matrix, triu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = selections['transaction_id'].tolist()\n",
    "columns = selections['fact_id'].tolist()\n",
    "cells = selections['weight'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = coo_matrix((cells, (rows, columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technical summary of the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy-to-read summary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row indices of selections can be accessed like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nonzero()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column indices of selections can be accessed like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.nonzero()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights of selections can be accessed like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, a sparse matrix can be transformed into a dense array like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix normalization\n",
    "Consider an academic field where transactions are publications, selections are citations, and facts are the references cited in a puplication. Further consider that the field is interdisciplinary: authors from one discipline cite 10 references on average, authors from another discipline cite 20 references on average. Intuitively, a reference that receives one citation out of 10 has a larger influence on the publication than one that receives one out of 20. By dividing a citation (selection) by the number of citations (selections) made, this difference can be accounted for. Mathematically, this amounts to a row normalization of the selection matrix $G$. This way of normalizing selections has first been proposed by Leydesdorff and Opthof (2010) for counting citations. Batagelj and Cerinšek (2013) have made it a pillar in their matrix formalism.\n",
    "\n",
    "For fast row normalization, we first transform $G$ to the [Compressed Sparse Row](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html) format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = G.tocsr()\n",
    "G.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The row-normalized matrix depicted in the middle of figure 1 is called $G^\\mathrm{N}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GN = normalize(G, norm='l1', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the normalized to the unnormalized selections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selections = pd.DataFrame(G.toarray())\n",
    "df_selections.index.name = 'transaction_id'\n",
    "df_selections.columns.name = 'fact_id'\n",
    "df_selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selections = pd.DataFrame(GN.toarray())\n",
    "df_selections.index.name = 'transaction_id'\n",
    "df_selections.columns.name = 'fact_id'\n",
    "df_selections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix projection\n",
    "The two bold arrows in figure 1 show the two projections that can be obtained via [matrix multiplication](https://en.wikipedia.org/wiki/Matrix_multiplication). Projection generally involves multiplications with the transposed selection matrix. The transpose of the selection matrix $G$ is called $G^\\mathrm{T}$ and has dimensionality $n\\times m$, i.e., the rows (columns) of $G$ are its columns (rows). Similarly, the transpose of the normalized selection matrix $G^\\mathrm{N}$ is $(G^\\mathrm{N})^\\mathrm{T}$.\n",
    "#### Projection to the transaction mode\n",
    "The first kind of projection results in transaction similarity matrices:\n",
    "\n",
    "- $H=G\\times G^\\mathrm{T}$ is a transaction similarity matrix where weights $x_{ik}\\in \\mathbb{N}$ are the numbers of facts co-selected by transactions $i$ and $k$;\n",
    "- $H^\\mathrm{N}=G^\\mathrm{N}\\times(G^\\mathrm{N})^\\mathrm{T}$ is a normalized transaction similarity matrix where weights $x_{ik}^\\mathrm{N}\\in \\mathbb{R}_{[0,1]}$ are the products of the normalized selections made in transactions $i$ and $k$, summed over all facts  $j$.\n",
    "\n",
    "$H^\\mathrm{N}$ is the complementary transformation of the one described by Batagelj and Cerinšek (2013, section 3.4). Transaction matrices are directed but symmetric. Weights $x_{ik}$ and $x_{ik}^\\mathrm{N}$ can be interpreted as transaction similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT = csr_matrix.transpose(G)\n",
    "GNT = csr_matrix.transpose(GN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that transposing a matrix in [Compressed Sparse Row](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html) format creates a matrix in [Compressed Sparse Column](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csc_matrix.html) format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(GT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = G*GT\n",
    "HN = GN*GNT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of a projected matrix is determined by the format of the first factor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(HN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since weights in transaction matrices can be interpreted as transaction similarities, there is no use in carrying along both triangular portions of the matrix. To remove a portion, transform the matrix into [COOrdinate](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_matrix.html) format, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HN = HN.tocoo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... remove the upper portion (you could just as well use ``tril()`` to remove the lower portion) of the matrix, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HN = triu(HN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and transform the matrix back into [Compressed Sparse Row](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html) format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HN = HN.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To draw $H^\\mathrm{N}$ as a graph, create an edge list, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities_norm = pd.concat([\n",
    "    pd.Series(HN.nonzero()[0]), \n",
    "    pd.Series(HN.nonzero()[1]), \n",
    "    pd.Series(HN.data)\n",
    "], axis=1)\n",
    "similarities_norm.columns = ['transaction_id_from', 'transaction_id_to', 'weight']\n",
    "similarities_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... construct the graph using ``compsoc``'s ``construct_graph(directed=False, ...)`` function described here, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn = cs.construct_graph(\n",
    "    directed=False, \n",
    "    multiplex=False, \n",
    "    graph_name='HN', \n",
    "    node_list=transactions, \n",
    "    edge_list=similarities_norm, \n",
    "    node_label='transaction'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and draw the graph using ``compsoc``'s custom ``draw_graph()`` wrapper described here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs.draw_graph(\n",
    "    hn, \n",
    "    node_pos=nx.circular_layout(hn), \n",
    "    node_size_factor=.25, \n",
    "    node_color=cs.uniform_vertex_property(hn, 'black'), \n",
    "    node_border_width=2, \n",
    "    edge_width_factor=50, \n",
    "    labels='text', \n",
    "    font_size_factor=2, \n",
    "    font_color='white', \n",
    "    figsize='small', \n",
    "    margins=.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Projection to the fact mode\n",
    "The second kind of projection results in fact co-selection matrices:\n",
    "\n",
    "- $I=G^\\mathrm{T}\\times G$ is a fact co-selection matrix where weights $y_{jl}\\in \\mathbb{N}$ are the numbers of transactions that co-select facts $j$ and $l$ (Batagelj and Cerinšek 2013, section 3.2);\n",
    "- $I^\\mathrm{N}=G^\\mathrm{T}\\times G^\\mathrm{N}$ is a normalized fact co-selection matrix where weights $y_{jl}^\\mathrm{N}\\in \\mathbb{R}_{\\geq0}$ are the normalized numbers of transactions that co-select facts $j$ and $l$ (Batagelj and Cerinšek 2013, section 3.3).\n",
    "\n",
    "Fact matrices are also directed and symmetric. It is these matrices that resemble **meaning structures**. According to our general model of complex socio-cultural systems, they emerge from the collective transactions in a field, and they harbor the patterns that agents observe and which influence future transactions via downward causation. Co-selection weights $y_{ik}$ and $y_{ik}^\\mathrm{N}$ of meaning structures can be interpreted as **catalyses**. Padgett & Powell (2012, chapter 4) have adapted this concept from chemistry to mean that the selection of a product in a social network entails – or makes more likely – the selection of another product (which results in a self-sustaining production cycle). Co-selection is mutual catalysis because the selection of a fact makes the selection of a co-selected fact more likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = GT*G\n",
    "IN = GT*GN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To correctly access indices and weights, co-selection matrices must be transformed from [Compressed Sparse Column](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csc_matrix.html) to [Compressed Sparse Row](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html) format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = I.tocsr()\n",
    "IN = IN.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform $I^\\mathrm{N}$ to an edge list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_selections_norm = pd.concat([\n",
    "    pd.Series(IN.nonzero()[0]), \n",
    "    pd.Series(IN.nonzero()[1]), \n",
    "    pd.Series(IN.data)\n",
    "], axis=1)\n",
    "co_selections_norm.columns = ['fact_id_from', 'fact_id_to', 'weight']\n",
    "co_selections_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of illustrating co-selections as mutual catalyses, set ``directed=True``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_in = cs.construct_graph(\n",
    "    directed=True, \n",
    "    multiplex=False, \n",
    "    graph_name='IN', \n",
    "    node_list=facts, \n",
    "    edge_list=co_selections_norm, \n",
    "    node_label='fact'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs.draw_graph(\n",
    "    _in, \n",
    "    node_pos=nx.circular_layout(_in), \n",
    "    node_size_factor=.25, \n",
    "    node_border_width=2, \n",
    "    edge_width_factor=25, \n",
    "    edge_transparency=.5, \n",
    "    curved_edges=True, \n",
    "    labels='text', \n",
    "    font_size_factor=2, \n",
    "    figsize='medium'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data enrichment\n",
    "Normalized fact co-selection matrices $I^\\mathrm{N}$ are additive, i.e., fact co-selections from additional transactions can simply be added to existing co-selection weights. Due to this nature, these matrices have a number of unique properties.\n",
    "\n",
    "The sum of all weights equals the sum of all weights in $G$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fact attributes\n",
    "The summed **weight** of rows or columns in $I^\\mathrm{N}$, i.e., the weighted in- or outdegree $w$ in the corresponding graph, equals the weighted number of selections per fact in the selection matrix $G$. Fact 5 (``fact_id=4``) has been selected most oftern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = IN.sum(axis=1)\n",
    "w = np.squeeze(np.array(w))\n",
    "w = pd.Series(w).round(4)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elements in the diagonal $d$ are a measure of how strongly, in absolute terms, the respective facts are **autocatalytic** or catalyze themselves. In our toy example, e.g., transaction 1 selects each of its five facts with a normalized weight of 0.2. Projection of just these five selections to the fact mode would result in a fully connected graph in which facts mutually catalyze each other (including themselves) with a weight of 0.2. Since fact 1 (``fact_id=0``) is not selected in any other transaction, 0.2 is also its final value of autocatalysis, stored in the matrix diagonal. While fact 5 has been selected most often, fact 9 (``fact_id=8``) ist most autocatalytic because it is not co-selected with any other fact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(IN.diagonal())\n",
    "a = pd.Series(a).round(4)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fraction of autocatalyses $a$ among all weighted selections $w$ can be turned into a measure of **embeddedness**, $e=1-a/w$. Here, embeddedness basically tells to what extent facts are co-selected. Facts 1 and 2 are most embedded because they are each co-selected among four other facts. Fact 5 is not embedded because it is not co-selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = (1-a/w).round(4)\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute facts' distinct co-selections or **degrees**, autocatalyses (loops) must be removed. This change of the sparsity structure is fastest using the [LInked List](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.lil_matrix.html) matrix format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_nodiag = IN.tolil()\n",
    "IN_nodiag.setdiag(values=0)\n",
    "IN_nodiag.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a degree of 6, fact 5 is most strongly connected to other facts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [len(i) for i in IN_nodiag.data.tolist()]\n",
    "k = pd.Series(k)\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A final score is most intuitive when facts are persons but also applies to cultural entities. A person that only goes to few parties but talks to many persons during those transactions may be called sociable. **Sociability** is the extent to which activity (measured as the number of selections $w$) is turned into connections $k$. Facts 1 and 2 are most sociable because one selection each results in four co-selections. Fact 5 is only moderately sociable because it took three selections to obtain six co-selections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = (k/w).round(4)\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these fact attributes, we can now enrich the ``facts`` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "facts_enriched = pd.concat([facts, k, w, a, e, s], axis=1)\n",
    "facts_enriched.columns = ['fact_id', 'fact', 'degree', 'weight', 'autocatalysis', 'embeddedness', 'sociability']\n",
    "facts_enriched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-warning'>\n",
    "<big><b>Caution</b></big>\n",
    "\n",
    "It is important to understand the effects of matrix normalization as we have discussed it so far. For example, a strong co-selection of two facts can result from few transactions in which few facts are co-selected or from many transactions in which many facts are co-selected. Matrix normalization complicates interpretability when the number of selections per transaction exhibits large variance. In small-data settings, it may therefore be advised to not use matrix normalization. In big-data settings, it may be possible to remove outlier transactions with exceptionally many selections (e.g., publications with either very short or very long reference lists).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative co-selection fractions\n",
    "Sometimes it is can be helpful to filter graphs, e.g., to uncover a pattern that may otherwise be hidden in relational \"noise\". An observer of a meaning structure may neglect weak ties to identify the core facts of the field. Hence, removing weakly selected nodes or edges is not only a step we can do as network analysts, but an analytical step towards understanding what an observer in a field may have observed as he or she was trying to reduce uncertainty.\n",
    "\n",
    "As an alternative to simply filtering edges with small weights, one can keep those co-selections that collectively account for a specified amount of attention in the field. For this purpose we enrich edges by **cumulative fractions** of total matrix weights.\n",
    "\n",
    "First, distinct edge weights and the weight (attention) they collectively account for are identified. In the toy example, a single co-selection tie with a ``weight == 1`` also accounts for a total weight of 1. But 16 co-selection ties with ``weight == 0.2`` account for a total weight of 3.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_selections_norm_cumfrac = co_selections_norm.copy()\n",
    "co_selections_norm_cumfrac.index = co_selections_norm_cumfrac.weight\n",
    "co_selections_norm_cumfrac = co_selections_norm_cumfrac['weight'].groupby(co_selections_norm_cumfrac.index).sum()\n",
    "co_selections_norm_cumfrac = co_selections_norm_cumfrac.sort_index(ascending=False)\n",
    "co_selections_norm_cumfrac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, the summed weights are turned into cumulative co-selection fractions ``cumfrac`` such that all weights at least as strong as the smallest one account for 100 percent of the attention in the whole field. In the toy example, if we wanted to keep those co-selections that account for no more than 75 percent of the attention (``cumfrac <= .75``), we would have to remove all edges with ``weight < 0.3333``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_selections_norm_cumfrac = co_selections_norm_cumfrac.cumsum()/sum(co_selections_norm_cumfrac)\n",
    "co_selections_norm_cumfrac = co_selections_norm_cumfrac.round(4)\n",
    "co_selections_norm_cumfrac.rename('cumfrac', inplace=True)\n",
    "co_selections_norm_cumfrac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cumulative fractions can then be merged back into the co-selection dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_selections_norm = pd.merge(left=co_selections_norm, right=co_selections_norm_cumfrac, left_on='weight', right_on=co_selections_norm_cumfrac.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the edge filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_selections_norm_filter = co_selections_norm[co_selections_norm['cumfrac'] <= .75]\n",
    "co_selections_norm_filter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And construct and draw the filtered meaning structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_filter = cs.construct_graph(\n",
    "    directed=True, \n",
    "    multiplex=False, \n",
    "    graph_name='IN_filter', \n",
    "    node_list=facts, \n",
    "    edge_list=co_selections_norm_filter, \n",
    "    node_label='fact'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs.draw_graph(\n",
    "    in_filter, \n",
    "    node_pos=nx.circular_layout(in_filter), \n",
    "    node_size_factor=.25, \n",
    "    node_border_width=2, \n",
    "    edge_width_factor=25, \n",
    "    edge_transparency=.5, \n",
    "    curved_edges=True, \n",
    "    labels='text', \n",
    "    font_size_factor=2, \n",
    "    figsize='medium'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function\n",
    "The ``project_selection_matrix()`` function performs all these steps with just a few parameter inputs. It has two additional features: First, to handle cases where transaction and fact identifiers are not integers from $0$ to $m$ or $n$, that normal form is created (using a function defined in lines 38-40). Second, for transaction matrices the degrees $k$ and selection weights $w$ of transactions are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_selection_matrix(\n",
    "    selections, \n",
    "    how, \n",
    "    transaction_id='transaction_id', \n",
    "    fact_id='fact_id', \n",
    "    norm=True, \n",
    "    remove_loops=True, \n",
    "    symmetrize=True\n",
    "):\n",
    "    '''\n",
    "    Description: This function uses the terminology of the compsoc unified data model \n",
    "        according to which \"transactions select facts\"; these selections are stored in a \n",
    "        selection matrics; the function projects a selection matrix to a transaction \n",
    "        similarity matrix or a fact co-selection matrix; computes fact attributes; \n",
    "        computes cumulative co-selection fractions for matrix filtering.\n",
    "    \n",
    "    Inputs:\n",
    "        selections: Dataframe containing the selection matrix indices and data; must \n",
    "            contain a 'weight' column that contains the cell weights.\n",
    "        how: String that specifies which projection is to be made; must be either \n",
    "            'transactions' or 'facts'; if 'transactions', then the matrix of transactions \n",
    "            coupled by facts will be created; if 'facts', then the matrix of facts \n",
    "            coupled by transactions will be created.\n",
    "        transaction_id: Name of the column of the dataframe ``selections`` that holds the \n",
    "            identifiers of the transactions selecting facts.\n",
    "        fact_id: Name of the column of the dataframe ``selections`` that holds the \n",
    "            identifiers of the facts getting selected in transactions.\n",
    "        norm: Boolean parameter specifying if matrix normalization should be performed.\n",
    "        remove_loops: Boolean parameter specifying if the matrix diagonal should be \n",
    "            removed; if False, loops will be included in computing cumulative \n",
    "            co-selection fractions.\n",
    "        symmetrize: Boolean parameter specifying if the lower portion of the matrix \n",
    "            should be removed.\n",
    "    \n",
    "    Output: A dataframe containing the projected matrices (enriched by cumulative \n",
    "        fractions in the case of a normalized projection to the fact mode); a dataframe \n",
    "        containing matrix-based attributes of transactions or facts (depending on the \n",
    "        type of projection)\n",
    "    '''\n",
    "    \n",
    "    # function\n",
    "    def get_unique(s):\n",
    "        l = s.unique().tolist()\n",
    "        return {identifier: index for index, identifier in enumerate(l)}\n",
    "    \n",
    "    # map identifiers of transactions and facts to unique integers\n",
    "    import pandas as pd\n",
    "    d_transactions_indices = get_unique(selections[transaction_id])\n",
    "    d_facts_indices = get_unique(selections[fact_id])\n",
    "    \n",
    "    # construct selection matrix\n",
    "    rows = [d_transactions_indices[transaction_id] for transaction_id in selections[transaction_id].values]\n",
    "    columns = [d_facts_indices[fact_id] for fact_id in selections[fact_id].values]\n",
    "    cells = selections['weight'].tolist()\n",
    "    from scipy.sparse import csr_matrix, coo_matrix, triu\n",
    "    G = coo_matrix((cells, (rows, columns))).tocsr()\n",
    "    GT = csr_matrix.transpose(G)\n",
    "    from sklearn.preprocessing import normalize\n",
    "    GN = normalize(G, norm='l1', axis=1)\n",
    "    \n",
    "    # project selection matrix ...\n",
    "    import numpy as np\n",
    "    \n",
    "    # ... to transaction similarity matrix\n",
    "    if how == 'transactions':\n",
    "        if norm == True:\n",
    "            GNT = csr_matrix.transpose(GN)\n",
    "            H = GN*GNT\n",
    "        else:\n",
    "            H = G*GT\n",
    "        \n",
    "        # derive transaction attributes dataframe\n",
    "        H_nodiag = H.tolil()\n",
    "        H_nodiag.setdiag(values=0)\n",
    "        \n",
    "        k = pd.Series([len(i) for i in H_nodiag.data.tolist()])\n",
    "        w = pd.Series(np.array(H.diagonal()))\n",
    "        if norm == True:\n",
    "            w = (1/w).round(4)\n",
    "        else:\n",
    "            w = w.round(4)\n",
    "        \n",
    "        d_indices_transactions = {index: identifier for identifier, index in d_transactions_indices.items()}\n",
    "        \n",
    "        transaction_attributes = pd.concat([pd.Series(d_indices_transactions), k, w], axis=1)\n",
    "        transaction_attributes.columns = [transaction_id, 'degree', 'weight']\n",
    "        \n",
    "        # construct similarities dataframe\n",
    "        if remove_loops == True:\n",
    "            H = H.tolil()\n",
    "            H.setdiag(0)\n",
    "\n",
    "        if symmetrize == True:\n",
    "            H = triu(H.tocoo()).tocsr()\n",
    "        else:\n",
    "            H = H.tocsr()\n",
    "        \n",
    "        transaction_id_from = [d_indices_transactions[index] for index in H.nonzero()[0].tolist()]\n",
    "        transaction_id_to = [d_indices_transactions[index] for index in H.nonzero()[1].tolist()]\n",
    "        weight = H.data.tolist()\n",
    "        \n",
    "        similarities = pd.concat([pd.Series(transaction_id_from), pd.Series(transaction_id_to), pd.Series(weight)], axis=1)\n",
    "        similarities.columns = [transaction_id+'_from', transaction_id+'_to', 'similarity']\n",
    "        \n",
    "        return similarities, transaction_attributes\n",
    "    \n",
    "    # ... to fact co-selection matrix\n",
    "    if how == 'facts':\n",
    "        if norm == True:\n",
    "            I = GT*GN\n",
    "        else:\n",
    "            I = GT*G\n",
    "        \n",
    "        # derive fact attributes dataframe\n",
    "        I_nodiag = I.tolil()\n",
    "        I_nodiag.setdiag(values=0)\n",
    "        \n",
    "        k = pd.Series([len(i) for i in I_nodiag.data.tolist()])\n",
    "        \n",
    "        d_indices_facts = {index: identifier for identifier, index in d_facts_indices.items()}\n",
    "        \n",
    "        if norm == True:\n",
    "            w = pd.Series(np.squeeze(np.array(I.sum(axis=1)))).round(4)\n",
    "            a = pd.Series(np.array(I.diagonal())).round(4)\n",
    "            e = (1-a/w).round(4)\n",
    "            s = (k/w).round(4)\n",
    "            \n",
    "            fact_attributes = pd.concat([pd.Series(d_indices_facts), k, w, a, e, s], axis=1)\n",
    "            fact_attributes.columns = [fact_id, 'degree', 'weight', 'autocatalysis', 'embeddedness', 'sociability']\n",
    "            \n",
    "        else:\n",
    "            fact_attributes = pd.concat([pd.Series(d_indices_facts), k], axis=1)\n",
    "            fact_attributes.columns = [fact_id, 'degree']\n",
    "        \n",
    "        # construct co-selections dataframe with cumulative co-selection fractions\n",
    "        if remove_loops == True:\n",
    "            I = I.tolil()\n",
    "            I.setdiag(0)\n",
    "        \n",
    "        if symmetrize == True:\n",
    "            I = triu(I.tocoo()).tocsr()\n",
    "        else:\n",
    "            I = I.tocsr()\n",
    "                \n",
    "        fact_id_from = [d_indices_facts[index] for index in I.nonzero()[0].tolist()]\n",
    "        fact_id_to = [d_indices_facts[index] for index in I.nonzero()[1].tolist()]\n",
    "        weight = I.data.tolist()\n",
    "        \n",
    "        co_selections = pd.concat([pd.Series(fact_id_from), pd.Series(fact_id_to), pd.Series(weight)], axis=1)\n",
    "        co_selections.columns = [fact_id+'_from', fact_id+'_to', 'weight']\n",
    "        \n",
    "        co_selections_cumfrac = co_selections.copy()\n",
    "        co_selections_cumfrac.index = co_selections_cumfrac.weight\n",
    "        co_selections_cumfrac = co_selections_cumfrac['weight'].groupby(co_selections_cumfrac.index).sum()\n",
    "        co_selections_cumfrac = co_selections_cumfrac.sort_index(ascending=False)\n",
    "        co_selections_cumfrac = co_selections_cumfrac.cumsum()/sum(co_selections_cumfrac)\n",
    "        co_selections_cumfrac = co_selections_cumfrac.round(4)\n",
    "        co_selections_cumfrac.rename('cumfrac', inplace=True)\n",
    "        \n",
    "        co_selections = pd.merge(left=co_selections, right=co_selections_cumfrac, left_on='weight', right_on=co_selections_cumfrac.index)\n",
    "        \n",
    "        return co_selections, fact_attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of the ``compsoc`` library, we can call this function, e.g., to compare the fact co-selection matrices with and without normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_normalization, _ = cs.project_selection_matrix(\n",
    "    selections=selections, \n",
    "    how='facts', \n",
    "    norm=True, \n",
    "    remove_loops=False, \n",
    "    symmetrize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(\n",
    "    data=with_normalization, \n",
    "    values='weight', \n",
    "    index='fact_id_from', \n",
    "    columns='fact_id_to'\n",
    ").round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "without_normalization, _ = cs.project_selection_matrix(\n",
    "    selections=selections, \n",
    "    how='facts', \n",
    "    norm=False, \n",
    "    remove_loops=False, \n",
    "    symmetrize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(\n",
    "    data=without_normalization, \n",
    "    values='weight', \n",
    "    index='fact_id_from', \n",
    "    columns='fact_id_to'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiplex data\n",
    "As we have just seen, the weight of edges in meaning structures is intimately related to the number of transactions and the number of selections per transaction in a field. If we simply filter co-selections in a field (using weights or cumulative fractions), we may unwillingly punish a subfield that is not as voluminous or exhibits a different style of behavior as another subfield. For example, an academic field may harbor subfields of different size (different number of publications) and with different publication practices (different conventions of how many references to cite in a publication). In such cases, it is advised to use multiplex data, i.e., to use one network layer per subfield. These layers are the different **domains** of social life. Each domain has its own **type of tie**, but domains can - and typically do - overlap in terms of facts. It is a beauty of the matrix formalism that a mapping of transactions to domains translates to a separate type of tie per domain in the meaning structure (see figure 1).\n",
    "\n",
    "### Function\n",
    "\n",
    "The ``meaning_structures()`` function is a software wrapper around the ``project_selection_matrix()`` function that is tailored to creating multi-layer meaning structures (it is restricted to projecting selection matrices to the fact mode). The ``multiplex`` parameter decides if multi-layer fact matrices are created. If ``multiplex=True``, a ``transactions`` dataframe must be provided that maps a ``transaction_id`` to a ``domain_id``. Consult the description below for details, e.g., about outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meaning_structures(\n",
    "    selections, \n",
    "    transaction_id, \n",
    "    fact_id, \n",
    "    multiplex=False, \n",
    "    transactions=None, \n",
    "    domain_id=None, \n",
    "    facts=None, \n",
    "    norm=True, \n",
    "    remove_loops=True, \n",
    "    symmetrize=True\n",
    "):\n",
    "    '''\n",
    "    Description: Projects a selection matrix to (multiplex) co-selection matrix.\n",
    "    \n",
    "    Inputs:\n",
    "        selections: Dataframe containing the selection matrix indices and data; must \n",
    "            contain a 'weight' column that contains the cell weights.\n",
    "        transaction_id: Name of the column of the dataframe ``selections`` that holds the \n",
    "            identifiers of the transactions selecting facts.\n",
    "        fact_id: Name of the column of the dataframe ``selections`` that holds the \n",
    "            identifiers of the facts getting selected in transactions.\n",
    "        multiplex: Boolean parameter specifying if selections occurr in multiple domains; \n",
    "            set to False by default.\n",
    "        transactions: Dataframe containing the ``transaction_id`` identifiers of the \n",
    "            ``selections`` dataframe; must be specified if ``multiplex=True``; set to None \n",
    "            by default.\n",
    "        domain_id: Name of the column of the dataframe ``transactions`` that holds the \n",
    "            identifiers of the domains the transactions belong to; must be an integer from \n",
    "            0 to d where d is the number of domains; must be specified if \n",
    "            ``multiplex=True``; set to None by default.\n",
    "        facts: Dataframe containing the ``fact_id`` identifiers of the ``selections`` \n",
    "            dataframe; if specified, it will be enriched by fact attributes; set to None \n",
    "            by default.\n",
    "        norm: Boolean parameter specifying if matrix normalization should be performed.\n",
    "        remove_loops: Boolean parameter specifying if the matrix diagonal should be \n",
    "            removed; if False, loops will be included in computing cumulative \n",
    "            co-selection fractions.\n",
    "        symmetrize: Boolean parameter specifying if the lower portion of the matrix \n",
    "            should be removed.\n",
    "    \n",
    "    Output: At least two dataframes will be returned: first, a dataframe containing the \n",
    "        co-selection matrix independent of domain; second, a dataframe containing fact \n",
    "        attributes (if no ``facts`` dataframe is provided), or an enriched ``facts`` \n",
    "        dataframe (if one is provided), independent of domain. When ``multiplex=True`` \n",
    "        two additional dataframes will be returned: third, a dataframe containing the \n",
    "        co-selection matrix for domains; fourth, a list of dataframes containing fact \n",
    "        attributes (if no ``facts`` dataframe is provided), or a list of enriched \n",
    "        ``facts`` dataframes (if a ``facts`` dataframe is provided), for domains.\n",
    "    '''\n",
    "    \n",
    "    if multiplex == True:\n",
    "        if transactions is None:\n",
    "            print('A transactions dataframe must be specified.')\n",
    "        else:\n",
    "            if domain_id is None:\n",
    "                print('The domain identifier for the transactions dataframe must be specified.')\n",
    "            else:\n",
    "                if domain_id not in transactions.columns:\n",
    "                    print('The specified domain identifier is not a column in the transactions dataframe.')\n",
    "                else:\n",
    "                    domain_ids = set(transactions[domain_id])\n",
    "                    if (len(domain_ids) > 1) & (min(domain_ids) == 0) & (max(domain_ids) == len(domain_ids)-1):\n",
    "                        \n",
    "                        # co-selections and fact attributes dataframes independent of domain\n",
    "                        co_selections, fact_attributes = project_selection_matrix(selections=selections, how='facts', transaction_id=transaction_id, fact_id=fact_id, norm=norm, remove_loops=remove_loops, symmetrize=symmetrize)\n",
    "                        \n",
    "                        # co-selections and fact attributes dataframes for domains\n",
    "                        co_selections_domain = pd.DataFrame(columns=[fact_id+'_from', fact_id+'_to', 'weight', 'cumfrac', domain_id])\n",
    "                        fact_attributes_domain = []\n",
    "                        facts_enriched_domain = []\n",
    "                        for identifier in set(transactions[domain_id]):\n",
    "                            df = selections[selections[transaction_id].isin(transactions[transactions[domain_id] == identifier][transaction_id])]\n",
    "                            df_co_selections, df_fact_attributes = project_selection_matrix(selections=df, how='facts', transaction_id=transaction_id, fact_id=fact_id, norm=norm, remove_loops=remove_loops, symmetrize=symmetrize)\n",
    "                            df_co_selections[domain_id] = identifier\n",
    "                            co_selections_domain = pd.concat([co_selections_domain, df_co_selections])\n",
    "                            if facts is None:\n",
    "                                fact_attributes_domain.append(df_fact_attributes)\n",
    "                            else:\n",
    "                                df_facts_enriched = pd.merge(left=facts, right=df_fact_attributes, on=fact_id, how='left')\n",
    "                                facts_enriched_domain.append(df_facts_enriched)\n",
    "                        co_selections_domain.reset_index(drop=True, inplace=True)\n",
    "                        if facts is None:\n",
    "                            return co_selections, fact_attributes, co_selections_domain, fact_attributes_domain\n",
    "                        else:\n",
    "                            facts_enriched = pd.merge(left=facts, right=fact_attributes, on=fact_id, how='left')\n",
    "                            \n",
    "                            return co_selections, facts_enriched, co_selections_domain, facts_enriched_domain\n",
    "                    else:\n",
    "                        print('The specified domain identifier does not contain multiple domains or domains are not coded as integers starting with zero.')\n",
    "    else:\n",
    "        \n",
    "        # co-selections and fact attributes dataframes independent of domain\n",
    "        co_selections, fact_attributes = project_selection_matrix(selections=selections, how='facts', transaction_id=transaction_id, fact_id=fact_id, norm=norm, remove_loops=remove_loops, symmetrize=symmetrize)\n",
    "        \n",
    "        if facts is None:\n",
    "            return co_selections, fact_attributes\n",
    "        else:\n",
    "            facts_enriched = pd.merge(left=facts, right=fact_attributes, on=fact_id, how='left')\n",
    "            \n",
    "            return co_selections, facts_enriched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to visualize the relationship of \n",
    "\n",
    "The ``transactions`` dataframe of the toy example contains the necessary mapping of ``transaction_id`` to ``domain_id``. To use those domain identifiers for coloring nodes using the ``draw_graph()`` function, we must create a dictionary with `transaction_id``\n",
    "\n",
    "[colorbrewer2.org](https://colorbrewer2.org/) is a great dource of color advice for cartography:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs.draw_graph(\n",
    "    hn, \n",
    "    node_pos=nx.circular_layout(hn), \n",
    "    node_size_factor=.25, \n",
    "    node_color=cs.partition_to_vertex_property(transactions['domain_id'], {0: '#e41a1c', 1: '#377eb8'}), \n",
    "    node_border_width=2, \n",
    "    edge_width_factor=50, \n",
    "    labels='text', \n",
    "    font_size_factor=2, \n",
    "    font_color='white', \n",
    "    figsize='small', \n",
    "    margins=.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call the ``meaning_structures()`` function to create multiplex fact matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, facts_enriched, co_selections_domain, _ = cs.meaning_structures(\n",
    "    selections=selections, \n",
    "    transaction_id='transaction_id', \n",
    "    fact_id='fact_id', \n",
    "    multiplex=True, \n",
    "    transactions=transactions, \n",
    "    domain_id='domain_id', \n",
    "    facts=facts, \n",
    "    symmetrize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_domain = cs.construct_graph(\n",
    "    directed=True, \n",
    "    multiplex=True, \n",
    "    graph_name='IN_domain', \n",
    "    node_list=facts, \n",
    "    edge_list=co_selections_domain[['fact_id_from', 'fact_id_to', 'weight', 'domain_id']], \n",
    "    node_label='fact'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs.draw_graph(\n",
    "    in_domain, \n",
    "    node_pos=nx.circular_layout(in_domain), \n",
    "    node_size_factor=.25, \n",
    "    node_border_width=2, \n",
    "    edge_width_factor=25, \n",
    "    edge_transparency=.5, \n",
    "    curved_edges=True, \n",
    "    labels='text', \n",
    "    font_size_factor=2, \n",
    "    figsize='medium'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
